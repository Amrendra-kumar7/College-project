import cv2
import numpy as np
from ultralytics import YOLO

# Load your custom YOLO model
model = YOLO('runs/detect/train/weights/best.pt')

# Open webcam
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

# Set webcam resolution
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

try:
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Error: Failed to capture frame.")
            break

        # Perform inference
        results = model(frame)

        # Process results
        current_detections = []
        for result in results:
            if result.boxes is not None:
                # Get class names and coordinates
                boxes = result.boxes.xyxy.cpu().numpy()
                class_indices = result.boxes.cls.cpu().numpy().astype(int)
                confidences = result.boxes.conf.cpu().numpy()

                for box, cls_idx, conf in zip(boxes, class_indices, confidences):
                    try:
                        label = f"{model.names[cls_idx]} {conf:.2f}"
                    except IndexError:
                        label = f"Unknown {conf:.2f}"
                    
                    # Draw bounding box and label using YOLO's plot method
                    frame = result.plot(img=frame, labels=False)  # Let's handle labels manually
                    
                    # Manually add label with larger text
                    x1, y1, x2, y2 = map(int, box[:4])
                    cv2.putText(frame, label, (x1, y1 - 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                    
                    current_detections.append(model.names[cls_idx] if cls_idx < len(model.names) else f"Class {cls_idx}")

        # Display real-time detection list
        unique_detections = list(set(current_detections))
        y_offset = 30
        cv2.putText(frame, "Detected Objects:", (10, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)
        y_offset += 40
        
        for obj in unique_detections:
            cv2.putText(frame, f"- {obj}", (10, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            y_offset += 30

        # Display frame
        cv2.imshow('Real-time Object Detection', frame)

        # Exit on 'q' press
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except Exception as e:
    print(f"An error occurred: {e}")

finally:
    cap.release()
    cv2.destroyAllWindows()
